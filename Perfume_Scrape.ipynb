{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e74a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pymongo import errors\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa212cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_crawledPerfumes(data):\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    Perfume_Database = client.Perfume_Database\n",
    "    crawled_perfumes = Perfume_Database[\"Crawled_Perfumes\"]\n",
    "    crawled_perfumes.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c154ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readall_CleanedCrawledPerfumes(query):\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    Perfume_Database = client[\"Perfume_Database\"]\n",
    "    crawled_perfumes = Perfume_Database[\"Cleared_Crawled_Perfumes\"]\n",
    "    data = crawled_perfumes.find(query)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec99aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfume_exists(url):\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    Perfume_Database = client[\"Perfume_Database\"]\n",
    "    Scraped_Perfumes = Perfume_Database[\"Scraped_Perfumes\"]\n",
    "    \n",
    "    res = Scraped_Perfumes.find_one({\"url\": url})\n",
    "    \n",
    "    if res:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4953a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_one_to_ScrapedPerfumes(perfume):\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    Perfume_Database = client.Perfume_Database\n",
    "    Scraped_Perfumes = Perfume_Database[\"Scraped_Perfumes\"]\n",
    "    Scraped_Perfumes.insert_one(perfume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8e026b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import selenium\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2ce88",
   "metadata": {},
   "source": [
    "Create a new profile path, and manually disable site data saving so fragrantica won't ask for cloudflare tests and also cookies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76024190",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def init_browser(): # MUST add settings to prevent chrome from saving site data\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"user-data-dir=B:\\Projects\\Perfume-DataScrape\\Chrome\");\n",
    "#     proxy = '127.0.0.1:9150'\n",
    "#     chrome_options.add_argument('--proxy-server=socks5://' + proxy)\n",
    "    \n",
    "    return Browser(\"chrome\", options=chrome_options, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7972de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_perfume(browser):\n",
    "    soup = bs(browser.html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b85c2",
   "metadata": {},
   "source": [
    "## Scrape the perfume page for Name, Company, Main Accords, Perfumer, Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "552d85f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_perfume_page(browser, url):\n",
    "    \n",
    "####################################################\n",
    "####### USE THIS FOR A SINGULAR PERFUME PAGE #######\n",
    "############### NOT THE SEARCH PAGE ###############\n",
    "###################################################\n",
    "    \n",
    "    soup = bs(browser.html, \"html.parser\")\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    ####### PULL FROM ORIGINAL NAME LIST #######\n",
    "    try:\n",
    "        perfume_name = soup.find_all(\"div\", class_=\"cell small-12\")[3].find_all(\"b\")[0].get_text()\n",
    "    except:\n",
    "        perfume_name = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        perfume_comp = soup.find_all(\"div\", class_=\"cell small-12\")[3].find_all(\"b\")[1].get_text()\n",
    "    except:\n",
    "        perfume_comp = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        perfume_image = soup.find_all(\"div\", class_=\"cell small-12\")[1].find(\"img\")[\"src\"]\n",
    "    except:\n",
    "        perfume_image = \"NA\"\n",
    "\n",
    "    try: \n",
    "        for_gender = soup.find(\"small\").get_text()\n",
    "    except:\n",
    "        for_gender = \"NA\"\n",
    "    \n",
    "    try:\n",
    "        rating = float(soup.find(\"p\", class_=\"info-note\").find_all(\"span\")[0].get_text())\n",
    "        number_votes = int(soup.find(\"p\", class_=\"info-note\").find_all(\"span\")[2].get_text().replace(',', ''))\n",
    "    except:\n",
    "        rating = \"NA\"\n",
    "        number_votes = \"NA\"\n",
    "        print(f\"{perfume_name} does not have a ranking\")\n",
    "\n",
    "    try:\n",
    "        description = soup.find_all(\"div\", class_=\"cell small-12\")[3].get_text()\n",
    "    except:\n",
    "        description = \"NA\"\n",
    "        print(f\"{perfume_name} does not have a description\")\n",
    "\n",
    "    ####### MAIN ACCORDS DICTIONARY #######\n",
    "\n",
    "    try:\n",
    "        main_accords = soup.find_all(\"div\", class_=\"cell accord-box\")\n",
    "        accords_dict = {}\n",
    "        for m in range(len(main_accords)):\n",
    "            accord_name = main_accords[m].get_text()\n",
    "            accord_value = float(main_accords[m].find(\"div\", class_=\"accord-bar\")[\"style\"].rsplit(\"width: \")[1].strip(\"%;\"))\n",
    "            accords_dict[accord_name] = accord_value\n",
    "    except:\n",
    "        accords_dict = {}\n",
    "        print(f\"{perfume_name} does not have accords\")\n",
    "\n",
    "    ####### FRAGRANCE NOTES #######        \n",
    "    notes = soup.find_all(\"div\", attrs={\"style\": \"display: flex; justify-content: center; text-align: center; flex-flow: wrap; align-items: flex-end; padding: 0.5rem;\"})\n",
    "\n",
    "    if len(notes) == 3:\n",
    "        number = 2\n",
    "        top_notes_list = []\n",
    "        middle_notes_list = []\n",
    "        base_notes_list = []\n",
    "\n",
    "        for n in range(len(notes[0].find_all(\"span\", class_=\"link-span\"))):\n",
    "            top_notes_list.append(notes[0].find_all(\"div\")[number].get_text())\n",
    "            number += 3\n",
    "\n",
    "        number = 2\n",
    "        for p in range(len(notes[1].find_all(\"span\", class_=\"link-span\"))):\n",
    "            middle_notes_list.append(notes[1].find_all(\"div\")[number].get_text())\n",
    "            number += 3\n",
    "\n",
    "        number = 2\n",
    "        for q in range(len(notes[2].find_all(\"span\", class_=\"link-span\"))):\n",
    "            base_notes_list.append(notes[2].find_all(\"div\")[number].get_text())\n",
    "            number += 3\n",
    "    elif len(notes) == 2:\n",
    "        number = 2\n",
    "        top_notes_list = []\n",
    "        middle_notes_list = []\n",
    "        base_notes_list = []\n",
    "\n",
    "        for r in range(len(notes[0].find_all(\"span\", class_=\"link-span\"))):\n",
    "            top_notes_list.append(notes[0].find_all(\"div\")[number].get_text())\n",
    "            number += 3\n",
    "\n",
    "        number = 2\n",
    "        for s in range(len(notes[1].find_all(\"span\", class_=\"link-span\"))):\n",
    "            middle_notes_list.append(notes[1].find_all(\"div\")[number].get_text())\n",
    "            number += 3\n",
    "    elif len(notes) == 1:\n",
    "        number = 2\n",
    "        top_notes_list = []\n",
    "        middle_notes_list = []\n",
    "        base_notes_list = []\n",
    "\n",
    "        for v in range(len(notes[0].find_all(\"span\", class_=\"link-span\"))):\n",
    "            middle_notes_list.append(notes[0].find_all(\"div\")[number].get_text())\n",
    "            number += 3\n",
    "    else:\n",
    "        top_notes_list = []\n",
    "        middle_notes_list = []\n",
    "        base_notes_list = []\n",
    "    \n",
    "    ####### VOTING DATA & INFORMATION #######\n",
    "    try:\n",
    "        voting = soup.find_all(\"div\", class_=\"cell small-1 medium-1 large-1\")\n",
    "    except:\n",
    "        voting = \"NA\"\n",
    "        \n",
    "    ####### Longevity #######\n",
    "    try:\n",
    "        long_v_weak = int(voting[0].get_text())\n",
    "    except:\n",
    "        long_v_weak = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        long_weak = int(voting[1].get_text())\n",
    "    except:\n",
    "        long_weak = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        long_moderate = int(voting[2].get_text())\n",
    "    except:\n",
    "        long_moderate = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        long_long_last = int(voting[3].get_text())\n",
    "    except:\n",
    "        long_long_last = \"NA\"\n",
    "    \n",
    "    try:\n",
    "        long_eternal = int(voting[4].get_text())\n",
    "    except:\n",
    "        long_eternal = \"NA\"\n",
    "    \n",
    "    \n",
    "    ####### Sillage #######\n",
    "    try:\n",
    "        sill_intimate = int(voting[5].get_text())\n",
    "    except:\n",
    "        sill_intimate = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        sill_intimate = int(voting[5].get_text())\n",
    "    except:\n",
    "        sill_intimate = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        sill_moderate = int(voting[6].get_text())\n",
    "    except:\n",
    "        sill_moderate = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        sill_strong = int(voting[7].get_text())\n",
    "    except:\n",
    "        sill_strong = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        sill_enormus = int(voting[8].get_text())\n",
    "    except:\n",
    "        sill_enormus = \"NA\"\n",
    "        \n",
    "    ####### Gender #######\n",
    "    try:\n",
    "        gender_female = int(voting[9].get_text())\n",
    "    except:\n",
    "        gender_female = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        gender_more_fem = int(voting[10].get_text())\n",
    "    except:\n",
    "        gender_more_fem = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        gender_unisex = int(voting[11].get_text())\n",
    "    except:\n",
    "        gender_unisex = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        gender_more_male = int(voting[12].get_text())\n",
    "    except:\n",
    "        gender_more_male = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        gender_male = int(voting[13].get_text())\n",
    "    except:\n",
    "        gender_male = \"NA\"\n",
    "        \n",
    "    ####### Price Value #######\n",
    "    try:\n",
    "        value_w_over = int(voting[14].get_text())\n",
    "    except:\n",
    "        value_w_over = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        value_over = int(voting[15].get_text())\n",
    "    except:\n",
    "        value_over = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        value_ok = int(voting[16].get_text())\n",
    "    except:\n",
    "        value_ok = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        value_good = int(voting[17].get_text())\n",
    "    except:\n",
    "        value_good = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        value_great = int(voting[18].get_text())\n",
    "    except:\n",
    "        value_great = \"NA\"  \n",
    "\n",
    "    ####### CREATING THE DICTIONARY OF DATA #######\n",
    "    perfume_dict = {\"url\": url,\n",
    "                    \"name\": perfume_name,\n",
    "                    \"company\": perfume_comp,\n",
    "                    \"image\": perfume_image,\n",
    "                    \"gender\": for_gender,\n",
    "                    \"rating\": rating,\n",
    "                    \"number_votes\": number_votes,\n",
    "                    \"main accords\": accords_dict,\n",
    "                    \"description\": description.replace(\"Read about this perfume in other languages: Deutsch, Español, Français, Čeština, Italiano, Русский, Polski, Português, Ελληνικά, 汉语, Nederlands, Srpski, Română, العربية, Українська, Монгол, עברית\", ''),\n",
    "                    \"top notes\": top_notes_list,\n",
    "                    \"middle notes\": middle_notes_list,\n",
    "                    \"base notes\": base_notes_list,\n",
    "                    \"longevity\":   {\"very weak\": long_v_weak,\n",
    "                                    \"weak\": long_weak,\n",
    "                                    \"moderate\": long_moderate,\n",
    "                                    \"long lasting\": long_long_last,\n",
    "                                    \"eternal\": long_eternal},\n",
    "                    \"sillage\":     {\"intimate\": sill_intimate,\n",
    "                                    \"moderate\": sill_moderate,\n",
    "                                    \"strong\": sill_strong,\n",
    "                                    \"enormous\": sill_enormus},\n",
    "                    \"gender_vote\": {\"female\": gender_female,\n",
    "                                    \"more female\": gender_more_fem,\n",
    "                                    \"unisex\": gender_unisex,\n",
    "                                    \"more male\": gender_more_male,\n",
    "                                    \"male\": gender_male},\n",
    "                    \"price value\": {\"way overpriced\": value_w_over,\n",
    "                                    \"overpriced\": value_over,\n",
    "                                    \"ok\": value_ok,\n",
    "                                    \"good value\": value_good,\n",
    "                                    \"great value\": value_great}\n",
    "                   }\n",
    "\n",
    "        \n",
    "    return perfume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac26ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_CrawledPerfumes(browser):\n",
    "    counter = 0\n",
    "    cooler = 60\n",
    "    crawled_perfumes_cursor = readall_CleanedCrawledPerfumes({}).limit(5000)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            crawled_perfume = crawled_perfumes_cursor.next()\n",
    "            \n",
    "            if not perfume_exists(crawled_perfume[\"link\"]):\n",
    "                \n",
    "                browser.visit(crawled_perfume[\"link\"])\n",
    "                \n",
    "                if am_I_blocked(browser):\n",
    "                    print(\"\\nI am BLOCKED\")\n",
    "                    print(f\"Waiting {cooler} seconds ...\\n\")\n",
    "                    time.sleep(cooler)\n",
    "                    browser.visit(crawled_perfume[\"link\"])\n",
    "                    \n",
    "                    while am_I_blocked(browser):\n",
    "                        cooler = cooler * 2\n",
    "                        print(\"\\nI am BLOCKED\")\n",
    "                        print(f\"Waiting {cooler} seconds ...\\n\")\n",
    "                        \n",
    "                        time.sleep(cooler)\n",
    "                        \n",
    "                        browser.visit(crawled_perfume[\"link\"])\n",
    "                else:\n",
    "                    perfume = scrape_perfume_page(browser, crawled_perfume['link'])\n",
    "                    write_one_to_ScrapedPerfumes(perfume)\n",
    "                    counter = counter +1\n",
    "\n",
    "                    print(f\"{counter}- Scraped and Saved {perfume['name']}.\")\n",
    "                            \n",
    "        except StopIteration:\n",
    "            print(\"\\n\")\n",
    "            print(\"==========================\")\n",
    "            print(\"Results are FINISHED.\")\n",
    "            break\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88f6691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def am_I_blocked(browser):\n",
    "    return browser.is_text_present(\"429 Too Many Requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3ef18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = init_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2e8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am BLOCKED\n",
      "Waiting 2 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 4 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 8 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 16 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 32 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 64 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 128 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 256 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 512 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 1024 seconds ...\n",
      "\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 2048 seconds ...\n",
      "\n",
      "1- Scraped and Saved PanAme.\n",
      "2- Scraped and Saved Ralph Wild.\n",
      "3- Scraped and Saved Naema.\n",
      "4- Scraped and Saved Angels' Share.\n",
      "5- Scraped and Saved Sweet Sunrise.\n",
      "6- Scraped and Saved Boss Bottled Parfum.\n",
      "7- Scraped and Saved Bouquet de Roses Relaxante.\n",
      "8- Scraped and Saved Nirvana White.\n",
      "9- Scraped and Saved Mademoiselle.\n",
      "\n",
      "I am BLOCKED\n",
      "Waiting 2048 seconds ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scrape_CrawledPerfumes(browser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
